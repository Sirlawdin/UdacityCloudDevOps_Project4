* 
* ==> Audit <==
* |---------|------|----------|--------|---------|---------------------|---------------------|
| Command | Args | Profile  |  User  | Version |     Start Time      |      End Time       |
|---------|------|----------|--------|---------|---------------------|---------------------|
| start   |      | minikube | ubuntu | v1.26.1 | 28 Aug 22 12:27 UTC | 28 Aug 22 12:28 UTC |
| start   |      | minikube | ubuntu | v1.26.1 | 28 Aug 22 13:55 UTC |                     |
|---------|------|----------|--------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2022/08/28 13:55:10
Running on machine: ip-172-31-14-65
Binary: Built with gc go1.18.3 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0828 13:55:10.568161    2520 out.go:296] Setting OutFile to fd 1 ...
I0828 13:55:10.568263    2520 out.go:348] isatty.IsTerminal(1) = true
I0828 13:55:10.568266    2520 out.go:309] Setting ErrFile to fd 2...
I0828 13:55:10.568271    2520 out.go:348] isatty.IsTerminal(2) = true
I0828 13:55:10.568379    2520 root.go:333] Updating PATH: /home/ubuntu/.minikube/bin
W0828 13:55:10.568479    2520 root.go:310] Error reading config file at /home/ubuntu/.minikube/config/config.json: open /home/ubuntu/.minikube/config/config.json: no such file or directory
I0828 13:55:10.571155    2520 out.go:303] Setting JSON to false
I0828 13:55:10.571836    2520 start.go:115] hostinfo: {"hostname":"ip-172-31-14-65","uptime":2950,"bootTime":1661691960,"procs":109,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"18.04","kernelVersion":"5.4.0-1078-aws","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"ec201baa-0059-20d6-5db4-6bcf7234e99e"}
I0828 13:55:10.571890    2520 start.go:125] virtualization:  
I0828 13:55:10.574085    2520 out.go:177] üòÑ  minikube v1.26.1 on Ubuntu 18.04
I0828 13:55:10.581028    2520 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0828 13:55:10.582461    2520 notify.go:193] Checking for updates...
I0828 13:55:10.583605    2520 driver.go:365] Setting default libvirt URI to qemu:///system
I0828 13:55:10.653318    2520 docker.go:137] docker version: linux-20.10.17
I0828 13:55:10.653395    2520 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0828 13:55:11.383839    2520 info.go:265] docker info: {ID:QFUP:JEW6:SGSH:HHUL:Y6HE:YZZW:AFW5:523Y:QBC7:OLX2:GPRW:Z7P4 Containers:3 ContainersRunning:0 ContainersPaused:0 ContainersStopped:3 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:false KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:24 OomKillDisable:true NGoroutines:34 SystemTime:2022-08-28 13:55:10.687088602 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:5.4.0-1078-aws OperatingSystem:Ubuntu 18.04.6 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:2 MemTotal:2040074240 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:ip-172-31-14-65 Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 Expected:9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No swap limit support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Experimental:true Name:app Path:/usr/libexec/docker/cli-plugins/docker-app SchemaVersion:0.1.0 ShortDescription:Docker App Vendor:Docker Inc. Version:v0.9.1-beta3] map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2-docker] map[Name:scan Path:/usr/libexec/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0828 13:55:11.383928    2520 docker.go:254] overlay module found
I0828 13:55:11.388119    2520 out.go:177] ‚ú®  Using the docker driver based on existing profile
I0828 13:55:11.390419    2520 start.go:284] selected driver: docker
I0828 13:55:11.390427    2520 start.go:808] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:1945 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/ubuntu:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0828 13:55:11.390522    2520 start.go:819] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0828 13:55:11.390598    2520 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0828 13:55:11.509444    2520 info.go:265] docker info: {ID:QFUP:JEW6:SGSH:HHUL:Y6HE:YZZW:AFW5:523Y:QBC7:OLX2:GPRW:Z7P4 Containers:3 ContainersRunning:0 ContainersPaused:0 ContainersStopped:3 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:false KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:24 OomKillDisable:true NGoroutines:34 SystemTime:2022-08-28 13:55:11.440798732 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:5.4.0-1078-aws OperatingSystem:Ubuntu 18.04.6 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:2 MemTotal:2040074240 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:ip-172-31-14-65 Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 Expected:9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No swap limit support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Experimental:true Name:app Path:/usr/libexec/docker/cli-plugins/docker-app SchemaVersion:0.1.0 ShortDescription:Docker App Vendor:Docker Inc. Version:v0.9.1-beta3] map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2-docker] map[Name:scan Path:/usr/libexec/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0828 13:55:11.512302    2520 out.go:177] 
W0828 13:55:11.514447    2520 out.go:239] üßØ  The requested memory allocation of 1945MiB does not leave room for system overhead (total system memory: 1945MiB). You may face stability issues.
W0828 13:55:11.514560    2520 out.go:239] üí°  Suggestion: Start minikube with less memory allocated: 'minikube start --memory=1945mb'
I0828 13:55:11.517292    2520 out.go:177] 
I0828 13:55:11.519248    2520 cni.go:95] Creating CNI manager for ""
I0828 13:55:11.519262    2520 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0828 13:55:11.519274    2520 start_flags.go:310] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:1945 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/ubuntu:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0828 13:55:11.525277    2520 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0828 13:55:11.530045    2520 cache.go:120] Beginning downloading kic base image for docker with docker
I0828 13:55:11.532124    2520 out.go:177] üöú  Pulling base image ...
I0828 13:55:11.535590    2520 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0828 13:55:11.535634    2520 preload.go:148] Found local preload: /home/ubuntu/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4
I0828 13:55:11.535639    2520 cache.go:57] Caching tarball of preloaded images
I0828 13:55:11.535825    2520 preload.go:174] Found /home/ubuntu/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0828 13:55:11.535839    2520 cache.go:60] Finished verifying existence of preloaded tar for  v1.24.3 on docker
I0828 13:55:11.535925    2520 profile.go:148] Saving config to /home/ubuntu/.minikube/profiles/minikube/config.json ...
I0828 13:55:11.536062    2520 image.go:75] Checking for gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon
I0828 13:55:11.617009    2520 image.go:79] Found gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon, skipping pull
I0828 13:55:11.617027    2520 cache.go:142] gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 exists in daemon, skipping load
I0828 13:55:11.617039    2520 cache.go:208] Successfully downloaded all kic artifacts
I0828 13:55:11.617062    2520 start.go:371] acquiring machines lock for minikube: {Name:mk923ca0cafdb7abb02570da09080d5be8735c7e Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0828 13:55:11.617175    2520 start.go:375] acquired machines lock for "minikube" in 91.29¬µs
I0828 13:55:11.617188    2520 start.go:95] Skipping create...Using existing machine configuration
I0828 13:55:11.617191    2520 fix.go:55] fixHost starting: 
I0828 13:55:11.617400    2520 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0828 13:55:11.678021    2520 fix.go:103] recreateIfNeeded on minikube: state=Stopped err=<nil>
W0828 13:55:11.678049    2520 fix.go:129] unexpected machine state, will restart: <nil>
I0828 13:55:11.680761    2520 out.go:177] üîÑ  Restarting existing docker container for "minikube" ...
I0828 13:55:11.682910    2520 cli_runner.go:164] Run: docker start minikube
I0828 13:55:12.151651    2520 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0828 13:55:12.191982    2520 kic.go:415] container "minikube" state is running.
I0828 13:55:12.192305    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:12.241903    2520 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0828 13:55:12.241977    2520 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0828 13:55:12.285294    2520 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/ubuntu/.minikube/machines/minikube/id_rsa Username:docker}
W0828 13:55:12.286461    2520 sshutil.go:64] dial failure (will retry): ssh: handshake failed: read tcp 127.0.0.1:57426->127.0.0.1:49157: read: connection reset by peer
I0828 13:55:12.286479    2520 retry.go:31] will retry after 276.165072ms: ssh: handshake failed: read tcp 127.0.0.1:57426->127.0.0.1:49157: read: connection reset by peer
W0828 13:55:12.563323    2520 sshutil.go:64] dial failure (will retry): ssh: handshake failed: read tcp 127.0.0.1:57430->127.0.0.1:49157: read: connection reset by peer
I0828 13:55:12.563338    2520 retry.go:31] will retry after 540.190908ms: ssh: handshake failed: read tcp 127.0.0.1:57430->127.0.0.1:49157: read: connection reset by peer
I0828 13:55:13.202725    2520 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0828 13:55:13.207212    2520 fix.go:57] fixHost completed within 1.590014762s
I0828 13:55:13.207226    2520 start.go:82] releasing machines lock for "minikube", held for 1.59004303s
W0828 13:55:13.207831    2520 start.go:602] error starting host: IPs output should only be one line, got 2 lines
W0828 13:55:13.207971    2520 out.go:239] ü§¶  StartHost failed, but will try again: IPs output should only be one line, got 2 lines
I0828 13:55:13.207987    2520 start.go:617] Will try again in 5 seconds ...
I0828 13:55:18.208142    2520 start.go:371] acquiring machines lock for minikube: {Name:mk923ca0cafdb7abb02570da09080d5be8735c7e Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0828 13:55:18.208255    2520 start.go:375] acquired machines lock for "minikube" in 94.52¬µs
I0828 13:55:18.208270    2520 start.go:95] Skipping create...Using existing machine configuration
I0828 13:55:18.208274    2520 fix.go:55] fixHost starting: 
I0828 13:55:18.208567    2520 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0828 13:55:18.245629    2520 fix.go:103] recreateIfNeeded on minikube: state=Running err=<nil>
W0828 13:55:18.245643    2520 fix.go:129] unexpected machine state, will restart: <nil>
I0828 13:55:18.247693    2520 out.go:177] üèÉ  Updating the running docker "minikube" container ...
I0828 13:55:18.249835    2520 machine.go:88] provisioning docker machine ...
I0828 13:55:18.249854    2520 ubuntu.go:169] provisioning hostname "minikube"
I0828 13:55:18.249891    2520 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0828 13:55:18.284817    2520 main.go:134] libmachine: Using SSH client type: native
I0828 13:55:18.284946    2520 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0828 13:55:18.284955    2520 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0828 13:55:18.431090    2520 main.go:134] libmachine: SSH cmd err, output: <nil>: minikube

I0828 13:55:18.431143    2520 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0828 13:55:18.465920    2520 main.go:134] libmachine: Using SSH client type: native
I0828 13:55:18.466055    2520 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0828 13:55:18.466067    2520 main.go:134] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0828 13:55:18.578198    2520 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0828 13:55:18.578212    2520 ubuntu.go:175] set auth options {CertDir:/home/ubuntu/.minikube CaCertPath:/home/ubuntu/.minikube/certs/ca.pem CaPrivateKeyPath:/home/ubuntu/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/ubuntu/.minikube/machines/server.pem ServerKeyPath:/home/ubuntu/.minikube/machines/server-key.pem ClientKeyPath:/home/ubuntu/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/ubuntu/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/ubuntu/.minikube}
I0828 13:55:18.578223    2520 ubuntu.go:177] setting up certificates
I0828 13:55:18.578230    2520 provision.go:83] configureAuth start
I0828 13:55:18.578269    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:18.615850    2520 provision.go:86] duration metric: configureAuth took 37.611777ms
W0828 13:55:18.615858    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.615872    2520 retry.go:31] will retry after 116.456¬µs: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.616967    2520 provision.go:83] configureAuth start
I0828 13:55:18.617015    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:18.654468    2520 provision.go:86] duration metric: configureAuth took 37.492263ms
W0828 13:55:18.654480    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.654492    2520 retry.go:31] will retry after 140.657¬µs: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.655585    2520 provision.go:83] configureAuth start
I0828 13:55:18.655634    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:18.690730    2520 provision.go:86] duration metric: configureAuth took 35.13463ms
W0828 13:55:18.690740    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.690751    2520 retry.go:31] will retry after 208.043¬µs: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.691798    2520 provision.go:83] configureAuth start
I0828 13:55:18.691841    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:18.741323    2520 provision.go:86] duration metric: configureAuth took 49.515656ms
W0828 13:55:18.741340    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.741352    2520 retry.go:31] will retry after 400.553¬µs: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.742437    2520 provision.go:83] configureAuth start
I0828 13:55:18.742495    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:18.781166    2520 provision.go:86] duration metric: configureAuth took 38.720748ms
W0828 13:55:18.781176    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.781187    2520 retry.go:31] will retry after 286.353¬µs: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.782297    2520 provision.go:83] configureAuth start
I0828 13:55:18.782347    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:18.817511    2520 provision.go:86] duration metric: configureAuth took 35.203198ms
W0828 13:55:18.817528    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.817540    2520 retry.go:31] will retry after 498.544¬µs: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.818622    2520 provision.go:83] configureAuth start
I0828 13:55:18.818659    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:18.852744    2520 provision.go:86] duration metric: configureAuth took 34.115294ms
W0828 13:55:18.852754    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.852766    2520 retry.go:31] will retry after 679.985¬µs: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.853829    2520 provision.go:83] configureAuth start
I0828 13:55:18.853866    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:18.893106    2520 provision.go:86] duration metric: configureAuth took 39.27036ms
W0828 13:55:18.893116    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.893128    2520 retry.go:31] will retry after 1.368432ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.895301    2520 provision.go:83] configureAuth start
I0828 13:55:18.895352    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:18.930250    2520 provision.go:86] duration metric: configureAuth took 34.940679ms
W0828 13:55:18.930260    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.930274    2520 retry.go:31] will retry after 2.601877ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.933413    2520 provision.go:83] configureAuth start
I0828 13:55:18.933457    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:18.993830    2520 provision.go:86] duration metric: configureAuth took 60.408782ms
W0828 13:55:18.993840    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.993851    2520 retry.go:31] will retry after 5.05007ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:18.998972    2520 provision.go:83] configureAuth start
I0828 13:55:18.999027    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.062122    2520 provision.go:86] duration metric: configureAuth took 63.137748ms
W0828 13:55:19.062132    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.062147    2520 retry.go:31] will retry after 4.118802ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.066585    2520 provision.go:83] configureAuth start
I0828 13:55:19.066644    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.101226    2520 provision.go:86] duration metric: configureAuth took 34.630508ms
W0828 13:55:19.101235    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.101246    2520 retry.go:31] will retry after 7.617463ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.109406    2520 provision.go:83] configureAuth start
I0828 13:55:19.109475    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.144118    2520 provision.go:86] duration metric: configureAuth took 34.698432ms
W0828 13:55:19.144127    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.144138    2520 retry.go:31] will retry after 10.613995ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.155368    2520 provision.go:83] configureAuth start
I0828 13:55:19.155424    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.192502    2520 provision.go:86] duration metric: configureAuth took 37.123316ms
W0828 13:55:19.192512    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.192528    2520 retry.go:31] will retry after 18.856469ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.211683    2520 provision.go:83] configureAuth start
I0828 13:55:19.211745    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.246292    2520 provision.go:86] duration metric: configureAuth took 34.587084ms
W0828 13:55:19.246303    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.246316    2520 retry.go:31] will retry after 22.859037ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.269511    2520 provision.go:83] configureAuth start
I0828 13:55:19.269607    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.302614    2520 provision.go:86] duration metric: configureAuth took 33.081345ms
W0828 13:55:19.302624    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.302636    2520 retry.go:31] will retry after 34.729413ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.337858    2520 provision.go:83] configureAuth start
I0828 13:55:19.337917    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.374076    2520 provision.go:86] duration metric: configureAuth took 36.20438ms
W0828 13:55:19.374087    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.374099    2520 retry.go:31] will retry after 77.447024ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.452406    2520 provision.go:83] configureAuth start
I0828 13:55:19.452466    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.485146    2520 provision.go:86] duration metric: configureAuth took 32.72607ms
W0828 13:55:19.485156    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.485167    2520 retry.go:31] will retry after 70.796181ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.556369    2520 provision.go:83] configureAuth start
I0828 13:55:19.556442    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.590453    2520 provision.go:86] duration metric: configureAuth took 34.070039ms
W0828 13:55:19.590464    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.590476    2520 retry.go:31] will retry after 103.923319ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.694800    2520 provision.go:83] configureAuth start
I0828 13:55:19.694867    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.727766    2520 provision.go:86] duration metric: configureAuth took 32.95082ms
W0828 13:55:19.727776    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.727788    2520 retry.go:31] will retry after 190.841051ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.919225    2520 provision.go:83] configureAuth start
I0828 13:55:19.919284    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:19.953316    2520 provision.go:86] duration metric: configureAuth took 34.078423ms
W0828 13:55:19.953326    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:19.953339    2520 retry.go:31] will retry after 356.026016ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:20.309761    2520 provision.go:83] configureAuth start
I0828 13:55:20.309835    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:20.347557    2520 provision.go:86] duration metric: configureAuth took 37.778009ms
W0828 13:55:20.347566    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:20.347579    2520 retry.go:31] will retry after 679.594431ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:21.027551    2520 provision.go:83] configureAuth start
I0828 13:55:21.027638    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:21.065716    2520 provision.go:86] duration metric: configureAuth took 38.150751ms
W0828 13:55:21.065725    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:21.065737    2520 retry.go:31] will retry after 593.393847ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:21.659296    2520 provision.go:83] configureAuth start
I0828 13:55:21.659364    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:21.695587    2520 provision.go:86] duration metric: configureAuth took 36.275825ms
W0828 13:55:21.695597    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:21.695609    2520 retry.go:31] will retry after 894.544307ms: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:22.590570    2520 provision.go:83] configureAuth start
I0828 13:55:22.590660    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:22.630323    2520 provision.go:86] duration metric: configureAuth took 39.739077ms
W0828 13:55:22.630332    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:22.630343    2520 retry.go:31] will retry after 2.108593507s: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:24.739071    2520 provision.go:83] configureAuth start
I0828 13:55:24.739158    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:24.773792    2520 provision.go:86] duration metric: configureAuth took 34.706406ms
W0828 13:55:24.773803    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:24.773814    2520 retry.go:31] will retry after 1.784202082s: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:26.558396    2520 provision.go:83] configureAuth start
I0828 13:55:26.558545    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:26.594911    2520 provision.go:86] duration metric: configureAuth took 36.500097ms
W0828 13:55:26.594922    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:26.594935    2520 retry.go:31] will retry after 5.171440736s: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:31.767447    2520 provision.go:83] configureAuth start
I0828 13:55:31.767529    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:31.832935    2520 provision.go:86] duration metric: configureAuth took 65.472449ms
W0828 13:55:31.832945    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:31.832969    2520 retry.go:31] will retry after 6.799168904s: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:38.632274    2520 provision.go:83] configureAuth start
I0828 13:55:38.632353    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:38.670727    2520 provision.go:86] duration metric: configureAuth took 38.439148ms
W0828 13:55:38.670740    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:38.670753    2520 retry.go:31] will retry after 8.725264106s: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:47.396154    2520 provision.go:83] configureAuth start
I0828 13:55:47.396220    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:47.434093    2520 provision.go:86] duration metric: configureAuth took 37.923826ms
W0828 13:55:47.434104    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:47.434117    2520 retry.go:31] will retry after 6.75350533s: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:54.187756    2520 provision.go:83] configureAuth start
I0828 13:55:54.187818    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:55:54.228936    2520 provision.go:86] duration metric: configureAuth took 41.168156ms
W0828 13:55:54.228946    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:55:54.228959    2520 retry.go:31] will retry after 12.623502512s: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:56:06.852566    2520 provision.go:83] configureAuth start
I0828 13:56:06.852646    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:56:06.894786    2520 provision.go:86] duration metric: configureAuth took 42.20747ms
W0828 13:56:06.894796    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:56:06.894810    2520 retry.go:31] will retry after 31.847522844s: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:56:38.742458    2520 provision.go:83] configureAuth start
I0828 13:56:38.742521    2520 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0828 13:56:38.779251    2520 provision.go:86] duration metric: configureAuth took 36.778593ms
W0828 13:56:38.779263    2520 ubuntu.go:180] configureAuth failed: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:56:38.779278    2520 ubuntu.go:189] Error configuring auth during provisioning Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:56:38.779288    2520 machine.go:91] provisioned docker machine in 1m20.529449101s
I0828 13:56:38.779342    2520 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0828 13:56:38.779380    2520 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0828 13:56:38.815918    2520 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/ubuntu/.minikube/machines/minikube/id_rsa Username:docker}
I0828 13:56:38.895350    2520 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0828 13:56:38.906052    2520 fix.go:57] fixHost completed within 1m20.69777053s
I0828 13:56:38.906065    2520 start.go:82] releasing machines lock for "minikube", held for 1m20.697803675s
W0828 13:56:38.906204    2520 out.go:239] üòø  Failed to start docker container. Running "minikube delete" may fix it: provision: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
I0828 13:56:38.909173    2520 out.go:177] 
W0828 13:56:38.912172    2520 out.go:239] ‚ùå  Exiting due to GUEST_PROVISION: Failed to start host: provision: Temporary Error: error getting ip during provisioning: IPs output should only be one line, got 2 lines
W0828 13:56:38.912193    2520 out.go:239] 
W0828 13:56:38.913102    2520 out.go:239] [31m‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m    üòø  If the above advice does not help, please let us know:                             [31m‚îÇ[0m
[31m‚îÇ[0m    üëâ  https://github.com/kubernetes/minikube/issues/new/choose                           [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m
I0828 13:56:38.915562    2520 out.go:177] 

* 
* ==> Docker <==
* -- Logs begin at Sun 2022-08-28 13:55:12 UTC, end at Sun 2022-08-28 13:58:00 UTC. --
Aug 28 13:55:13 minikube systemd[1]: Starting Docker Application Container Engine...
Aug 28 13:55:13 minikube dockerd[251]: time="2022-08-28T13:55:13.882913474Z" level=info msg="Starting up"
Aug 28 13:55:13 minikube dockerd[251]: time="2022-08-28T13:55:13.894981844Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Aug 28 13:55:13 minikube dockerd[251]: time="2022-08-28T13:55:13.895128540Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Aug 28 13:55:13 minikube dockerd[251]: time="2022-08-28T13:55:13.895769446Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Aug 28 13:55:13 minikube dockerd[251]: time="2022-08-28T13:55:13.895845641Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Aug 28 13:55:13 minikube dockerd[251]: time="2022-08-28T13:55:13.906477687Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Aug 28 13:55:13 minikube dockerd[251]: time="2022-08-28T13:55:13.906503093Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Aug 28 13:55:13 minikube dockerd[251]: time="2022-08-28T13:55:13.906524444Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Aug 28 13:55:13 minikube dockerd[251]: time="2022-08-28T13:55:13.906535659Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Aug 28 13:55:13 minikube dockerd[251]: time="2022-08-28T13:55:13.935539809Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.011855895Z" level=warning msg="Your kernel does not support swap memory limit"
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.011884993Z" level=warning msg="Your kernel does not support CPU realtime scheduler"
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.011894549Z" level=warning msg="Your kernel does not support cgroup blkio weight"
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.011908420Z" level=warning msg="Your kernel does not support cgroup blkio weight_device"
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.012435576Z" level=info msg="Loading containers: start."
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.189627422Z" level=info msg="Fixing inconsistent endpoint_cnt for network host. Expected=0, Actual=1"
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.220471271Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.277856556Z" level=info msg="Loading containers: done."
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.361288888Z" level=info msg="Docker daemon" commit=a89b842 graphdriver(s)=overlay2 version=20.10.17
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.362028804Z" level=info msg="Daemon has completed initialization"
Aug 28 13:55:14 minikube systemd[1]: Started Docker Application Container Engine.
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.387704395Z" level=info msg="API listen on [::]:2376"
Aug 28 13:55:14 minikube dockerd[251]: time="2022-08-28T13:55:14.410150103Z" level=info msg="API listen on /var/run/docker.sock"

* 
* ==> container status <==
* CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID
09220f943015b       6e38f40d628db       About an hour ago   Exited              storage-provisioner       1                   665b484c53e05
9078de46c2865       a4ca41631cc7a       About an hour ago   Exited              coredns                   0                   57c739dede7e4
646aca1254bc9       2ae1ba6417cbc       About an hour ago   Exited              kube-proxy                0                   d8409b8c07a21
04f671fdac276       6e38f40d628db       About an hour ago   Exited              storage-provisioner       0                   665b484c53e05
d37adbb8858db       d521dd763e2e3       About an hour ago   Exited              kube-apiserver            0                   ae69549e5d014
741e8b4d98fde       aebe758cef4cd       About an hour ago   Exited              etcd                      0                   ff1756becd164
337b29c45e6f3       3a5aa3a515f5d       About an hour ago   Exited              kube-scheduler            0                   a007ff6edfe80
15fc8e4ef98a2       586c112956dfc       About an hour ago   Exited              kube-controller-manager   0                   aaf831bffb008

* 
* ==> coredns [9078de46c286] <==
* .:53
[INFO] plugin/reload: Running configuration MD5 = cec3c60eb1cc4909fd4579a8d79ea031
CoreDNS-1.8.6
linux/amd64, go1.17.1, 13a9191
[INFO] SIGTERM: Shutting down servers then terminating
[INFO] plugin/health: Going into lameduck mode for 5s

* 
* ==> describe nodes <==
* 
* ==> dmesg <==
* [Aug28 13:06] MDS CPU bug present and SMT on, data leak possible. See https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/mds.html for more details.
[  +0.123951] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge.
[  +1.243124] i8042: Warning: Keylock active
[  +0.052680] platform eisa.0: EISA: Cannot allocate resource for mainboard
[  +0.004690] platform eisa.0: Cannot allocate resource for EISA slot 1
[  +0.004713] platform eisa.0: Cannot allocate resource for EISA slot 2
[  +0.004502] platform eisa.0: Cannot allocate resource for EISA slot 3
[  +0.004563] platform eisa.0: Cannot allocate resource for EISA slot 4
[  +0.004636] platform eisa.0: Cannot allocate resource for EISA slot 5
[  +0.004668] platform eisa.0: Cannot allocate resource for EISA slot 6
[  +0.004500] platform eisa.0: Cannot allocate resource for EISA slot 7
[  +0.004518] platform eisa.0: Cannot allocate resource for EISA slot 8
[  +0.331979] ena 0000:00:05.0: LLQ is not supported Fallback to host mode policy.
[ +11.459743] new mount options do not match the existing superblock, will be ignored
[  +1.885405] kauditd_printk_skb: 15 callbacks suppressed

* 
* ==> etcd [741e8b4d98fd] <==
* {"level":"info","ts":"2022-08-28T12:28:36.796Z","caller":"embed/etcd.go:479","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2022-08-28T12:28:36.799Z","caller":"embed/etcd.go:139","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"]}
{"level":"info","ts":"2022-08-28T12:28:36.799Z","caller":"embed/etcd.go:308","msg":"starting an etcd server","etcd-version":"3.5.3","git-sha":"0452feec7","go-version":"go1.16.15","go-os":"linux","go-arch":"amd64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":false,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"minikube=https://192.168.49.2:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-size-bytes":2147483648,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2022-08-28T12:28:36.807Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"6.471657ms"}
{"level":"info","ts":"2022-08-28T12:28:36.822Z","caller":"etcdserver/raft.go:448","msg":"starting local member","local-member-id":"aec36adc501070cc","cluster-id":"fa54960ea34d58be"}
{"level":"info","ts":"2022-08-28T12:28:36.823Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=()"}
{"level":"info","ts":"2022-08-28T12:28:36.823Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 0"}
{"level":"info","ts":"2022-08-28T12:28:36.823Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2022-08-28T12:28:36.823Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 1"}
{"level":"info","ts":"2022-08-28T12:28:36.825Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"warn","ts":"2022-08-28T12:28:36.828Z","caller":"auth/store.go:1220","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2022-08-28T12:28:36.831Z","caller":"mvcc/kvstore.go:415","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2022-08-28T12:28:36.832Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2022-08-28T12:28:36.835Z","caller":"etcdserver/server.go:851","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.3","cluster-version":"to_be_decided"}
{"level":"info","ts":"2022-08-28T12:28:36.838Z","caller":"etcdserver/server.go:736","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"aec36adc501070cc","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2022-08-28T12:28:36.843Z","caller":"embed/etcd.go:688","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2022-08-28T12:28:36.856Z","caller":"embed/etcd.go:277","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2022-08-28T12:28:36.856Z","caller":"embed/etcd.go:763","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2022-08-28T12:28:36.858Z","caller":"embed/etcd.go:581","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2022-08-28T12:28:36.858Z","caller":"embed/etcd.go:553","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2022-08-28T12:28:36.858Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2022-08-28T12:28:36.859Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","added-peer-id":"aec36adc501070cc","added-peer-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2022-08-28T12:28:36.926Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 1"}
{"level":"info","ts":"2022-08-28T12:28:36.926Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 1"}
{"level":"info","ts":"2022-08-28T12:28:36.926Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 1"}
{"level":"info","ts":"2022-08-28T12:28:36.926Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 2"}
{"level":"info","ts":"2022-08-28T12:28:36.926Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 2"}
{"level":"info","ts":"2022-08-28T12:28:36.926Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 2"}
{"level":"info","ts":"2022-08-28T12:28:36.926Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 2"}
{"level":"info","ts":"2022-08-28T12:28:36.926Z","caller":"etcdserver/server.go:2507","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2022-08-28T12:28:36.928Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","cluster-version":"3.5"}
{"level":"info","ts":"2022-08-28T12:28:36.928Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2022-08-28T12:28:36.928Z","caller":"etcdserver/server.go:2531","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2022-08-28T12:28:36.928Z","caller":"etcdserver/server.go:2042","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2022-08-28T12:28:36.928Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2022-08-28T12:28:36.930Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"192.168.49.2:2379"}
{"level":"info","ts":"2022-08-28T12:28:36.931Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2022-08-28T12:28:36.936Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2022-08-28T12:28:36.940Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2022-08-28T12:28:36.940Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2022-08-28T12:38:38.731Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":566}
{"level":"info","ts":"2022-08-28T12:38:38.737Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":566,"took":"459.902¬µs"}
{"level":"info","ts":"2022-08-28T12:43:38.736Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":776}
{"level":"info","ts":"2022-08-28T12:43:38.736Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":776,"took":"305.262¬µs"}
{"level":"info","ts":"2022-08-28T12:48:38.741Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":986}
{"level":"info","ts":"2022-08-28T12:48:38.755Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":986,"took":"14.044713ms"}
{"level":"info","ts":"2022-08-28T12:53:38.745Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":1196}
{"level":"info","ts":"2022-08-28T12:53:38.755Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":1196,"took":"6.766072ms"}
{"level":"info","ts":"2022-08-28T12:58:38.751Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":1406}
{"level":"info","ts":"2022-08-28T12:58:38.753Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":1406,"took":"1.072516ms"}
{"level":"info","ts":"2022-08-28T13:03:38.757Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":1616}
{"level":"info","ts":"2022-08-28T13:03:38.758Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":1616,"took":"480.351¬µs"}
{"level":"info","ts":"2022-08-28T13:04:30.796Z","caller":"osutil/interrupt_unix.go:64","msg":"received signal; shutting down","signal":"terminated"}
{"level":"info","ts":"2022-08-28T13:04:30.801Z","caller":"embed/etcd.go:368","msg":"closing etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}
WARNING: 2022/08/28 13:04:30 [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1:2379 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
WARNING: 2022/08/28 13:04:30 [core] grpc: addrConn.createTransport failed to connect to {192.168.49.2:2379 192.168.49.2:2379 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 192.168.49.2:2379: connect: connection refused". Reconnecting...
{"level":"info","ts":"2022-08-28T13:04:30.921Z","caller":"etcdserver/server.go:1453","msg":"skipped leadership transfer for single voting member cluster","local-member-id":"aec36adc501070cc","current-leader-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2022-08-28T13:04:30.932Z","caller":"embed/etcd.go:563","msg":"stopping serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2022-08-28T13:04:30.939Z","caller":"embed/etcd.go:568","msg":"stopped serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2022-08-28T13:04:30.939Z","caller":"embed/etcd.go:370","msg":"closed etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}

* 
* ==> kernel <==
*  13:58:01 up 52 min,  0 users,  load average: 0.08, 0.02, 0.01
Linux minikube 5.4.0-1078-aws #84~18.04.1-Ubuntu SMP Fri Jun 3 12:59:49 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 20.04.4 LTS"

* 
* ==> kube-apiserver [d37adbb8858d] <==
* W0828 13:04:36.360690       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.362962       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.365215       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.396707       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.399080       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.440667       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.468184       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.477537       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.575079       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.615826       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.655071       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.661667       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:36.736267       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:38.929154       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.090798       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.140578       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.240934       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.319462       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.366840       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.366841       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.395504       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.416075       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.450562       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.498678       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.538894       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.564521       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.566908       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.570304       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.574702       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.589336       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.626580       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.633248       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.659430       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.661786       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.751206       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.815523       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.922093       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.922269       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:39.967836       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.062228       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.082890       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.085232       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.137565       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.154439       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.178793       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.196573       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.202947       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.211392       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.295840       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.362787       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.386151       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.388477       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.411516       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.423947       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.425327       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.438875       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.441438       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.468989       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.493389       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
W0828 13:04:40.497846       1 clientconn.go:1331] [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...

* 
* ==> kube-controller-manager [15fc8e4ef98a] <==
* I0828 12:28:56.453809       1 resource_quota_controller.go:273] Starting resource quota controller
I0828 12:28:56.453965       1 shared_informer.go:255] Waiting for caches to sync for resource quota
I0828 12:28:56.454052       1 resource_quota_monitor.go:308] QuotaMonitor running
I0828 12:28:56.585412       1 controllermanager.go:593] Started "job"
I0828 12:28:56.586186       1 job_controller.go:184] Starting job controller
I0828 12:28:56.586311       1 shared_informer.go:255] Waiting for caches to sync for job
I0828 12:28:56.602298       1 shared_informer.go:255] Waiting for caches to sync for resource quota
W0828 12:28:56.613430       1 actual_state_of_world.go:541] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="minikube" does not exist
I0828 12:28:56.621841       1 shared_informer.go:262] Caches are synced for cronjob
I0828 12:28:56.634514       1 shared_informer.go:262] Caches are synced for certificate-csrapproving
I0828 12:28:56.636153       1 shared_informer.go:262] Caches are synced for ReplicaSet
I0828 12:28:56.635259       1 shared_informer.go:262] Caches are synced for ClusterRoleAggregator
I0828 12:28:56.642852       1 shared_informer.go:262] Caches are synced for TTL after finished
I0828 12:28:56.643056       1 shared_informer.go:262] Caches are synced for ephemeral
I0828 12:28:56.643248       1 shared_informer.go:262] Caches are synced for ReplicationController
I0828 12:28:56.651745       1 shared_informer.go:262] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0828 12:28:56.652570       1 shared_informer.go:262] Caches are synced for certificate-csrsigning-kubelet-serving
I0828 12:28:56.652684       1 shared_informer.go:262] Caches are synced for certificate-csrsigning-kubelet-client
I0828 12:28:56.658237       1 shared_informer.go:255] Waiting for caches to sync for garbage collector
I0828 12:28:56.659286       1 shared_informer.go:262] Caches are synced for node
I0828 12:28:56.659424       1 range_allocator.go:173] Starting range CIDR allocator
I0828 12:28:56.659529       1 shared_informer.go:255] Waiting for caches to sync for cidrallocator
I0828 12:28:56.659638       1 shared_informer.go:262] Caches are synced for cidrallocator
I0828 12:28:56.660124       1 shared_informer.go:262] Caches are synced for certificate-csrsigning-legacy-unknown
I0828 12:28:56.663972       1 shared_informer.go:262] Caches are synced for endpoint
I0828 12:28:56.669209       1 range_allocator.go:374] Set node minikube PodCIDR to [10.244.0.0/24]
I0828 12:28:56.669627       1 shared_informer.go:262] Caches are synced for GC
I0828 12:28:56.685545       1 shared_informer.go:262] Caches are synced for PV protection
I0828 12:28:56.685545       1 shared_informer.go:262] Caches are synced for expand
I0828 12:28:56.685715       1 shared_informer.go:262] Caches are synced for endpoint_slice_mirroring
I0828 12:28:56.685745       1 shared_informer.go:262] Caches are synced for PVC protection
I0828 12:28:56.686075       1 shared_informer.go:262] Caches are synced for bootstrap_signer
I0828 12:28:56.686249       1 shared_informer.go:262] Caches are synced for namespace
I0828 12:28:56.686837       1 shared_informer.go:262] Caches are synced for deployment
I0828 12:28:56.690341       1 shared_informer.go:262] Caches are synced for TTL
I0828 12:28:56.695029       1 shared_informer.go:262] Caches are synced for job
I0828 12:28:56.695168       1 shared_informer.go:262] Caches are synced for endpoint_slice
I0828 12:28:56.695426       1 shared_informer.go:262] Caches are synced for crt configmap
I0828 12:28:56.695654       1 shared_informer.go:262] Caches are synced for attach detach
I0828 12:28:56.698613       1 shared_informer.go:262] Caches are synced for service account
I0828 12:28:56.700190       1 shared_informer.go:262] Caches are synced for HPA
I0828 12:28:56.715924       1 shared_informer.go:262] Caches are synced for stateful set
I0828 12:28:56.736053       1 shared_informer.go:262] Caches are synced for taint
I0828 12:28:56.737885       1 node_lifecycle_controller.go:1399] Initializing eviction metric for zone: 
I0828 12:28:56.738324       1 taint_manager.go:187] "Starting NoExecuteTaintManager"
W0828 12:28:56.738135       1 node_lifecycle_controller.go:1014] Missing timestamp for Node minikube. Assuming now as a timestamp.
I0828 12:28:56.739689       1 node_lifecycle_controller.go:1215] Controller detected that zone  is now in state Normal.
I0828 12:28:56.740292       1 event.go:294] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0828 12:28:56.740547       1 shared_informer.go:262] Caches are synced for daemon sets
I0828 12:28:56.744057       1 shared_informer.go:262] Caches are synced for persistent volume
I0828 12:28:56.854786       1 shared_informer.go:262] Caches are synced for resource quota
I0828 12:28:56.904793       1 shared_informer.go:262] Caches are synced for resource quota
I0828 12:28:56.907768       1 shared_informer.go:262] Caches are synced for disruption
I0828 12:28:56.907829       1 disruption.go:371] Sending events to api server.
I0828 12:28:57.308724       1 shared_informer.go:262] Caches are synced for garbage collector
I0828 12:28:57.308745       1 garbagecollector.go:158] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
I0828 12:28:57.359334       1 shared_informer.go:262] Caches are synced for garbage collector
I0828 12:28:57.391871       1 event.go:294] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-6d4b75cb6d to 1"
I0828 12:28:57.594181       1 event.go:294] "Event occurred" object="kube-system/kube-proxy" fieldPath="" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-68rtb"
I0828 12:28:57.691372       1 event.go:294] "Event occurred" object="kube-system/coredns-6d4b75cb6d" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-6d4b75cb6d-72brk"

* 
* ==> kube-proxy [646aca1254bc] <==
* I0828 12:28:58.908673       1 node.go:163] Successfully retrieved node IP: 192.168.49.2
I0828 12:28:58.909020       1 server_others.go:138] "Detected node IP" address="192.168.49.2"
I0828 12:28:58.909195       1 server_others.go:578] "Unknown proxy mode, assuming iptables proxy" proxyMode=""
I0828 12:28:58.997987       1 server_others.go:206] "Using iptables Proxier"
I0828 12:28:58.998212       1 server_others.go:213] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I0828 12:28:58.998317       1 server_others.go:214] "Creating dualStackProxier for iptables"
I0828 12:28:58.998407       1 server_others.go:501] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, , defaulting to no-op detect-local for IPv6"
I0828 12:28:58.998514       1 proxier.go:259] "Setting route_localnet=1, use nodePortAddresses to filter loopback addresses for NodePorts to skip it https://issues.k8s.io/90259"
I0828 12:28:58.998866       1 proxier.go:259] "Setting route_localnet=1, use nodePortAddresses to filter loopback addresses for NodePorts to skip it https://issues.k8s.io/90259"
I0828 12:28:59.004544       1 server.go:661] "Version info" version="v1.24.3"
I0828 12:28:59.004570       1 server.go:663] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0828 12:28:59.011840       1 config.go:317] "Starting service config controller"
I0828 12:28:59.013724       1 shared_informer.go:255] Waiting for caches to sync for service config
I0828 12:28:59.013793       1 config.go:444] "Starting node config controller"
I0828 12:28:59.013802       1 shared_informer.go:255] Waiting for caches to sync for node config
I0828 12:28:59.016356       1 config.go:226] "Starting endpoint slice config controller"
I0828 12:28:59.016373       1 shared_informer.go:255] Waiting for caches to sync for endpoint slice config
I0828 12:28:59.113883       1 shared_informer.go:262] Caches are synced for node config
I0828 12:28:59.113919       1 shared_informer.go:262] Caches are synced for service config
I0828 12:28:59.116906       1 shared_informer.go:262] Caches are synced for endpoint slice config

* 
* ==> kube-scheduler [337b29c45e6f] <==
* I0828 12:28:39.177646       1 serving.go:348] Generated self-signed cert in-memory
W0828 12:28:41.677018       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0828 12:28:41.677063       1 authentication.go:346] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0828 12:28:41.677079       1 authentication.go:347] Continuing without authentication configuration. This may treat all requests as anonymous.
W0828 12:28:41.677088       1 authentication.go:348] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0828 12:28:41.730593       1 server.go:147] "Starting Kubernetes Scheduler" version="v1.24.3"
I0828 12:28:41.730949       1 server.go:149] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0828 12:28:41.739539       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0828 12:28:41.739697       1 shared_informer.go:255] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0828 12:28:41.742469       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I0828 12:28:41.744794       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
W0828 12:28:41.751505       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0828 12:28:41.751761       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0828 12:28:41.752945       1 reflector.go:324] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0828 12:28:41.752974       1 reflector.go:138] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0828 12:28:41.752584       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0828 12:28:41.756164       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0828 12:28:41.752637       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0828 12:28:41.752684       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0828 12:28:41.752751       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0828 12:28:41.752830       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0828 12:28:41.756857       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0828 12:28:41.757004       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0828 12:28:41.757116       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0828 12:28:41.757282       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0828 12:28:41.765354       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0828 12:28:41.765598       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0828 12:28:41.765550       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0828 12:28:41.768151       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0828 12:28:41.765896       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0828 12:28:41.768423       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0828 12:28:41.765974       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0828 12:28:41.768651       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0828 12:28:41.768893       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0828 12:28:41.769207       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0828 12:28:41.769052       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0828 12:28:41.769531       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0828 12:28:41.769115       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0828 12:28:41.769840       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0828 12:28:41.769167       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0828 12:28:41.770116       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0828 12:28:42.620082       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0828 12:28:42.620137       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0828 12:28:42.668452       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0828 12:28:42.668491       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0828 12:28:42.692250       1 reflector.go:324] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0828 12:28:42.692286       1 reflector.go:138] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0828 12:28:42.706136       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0828 12:28:42.706167       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
I0828 12:28:44.540483       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0828 13:04:31.035531       1 secure_serving.go:255] Stopped listening on 127.0.0.1:10259
I0828 13:04:31.038565       1 tlsconfig.go:255] "Shutting down DynamicServingCertificateController"
I0828 13:04:31.039910       1 configmap_cafile_content.go:223] "Shutting down controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"

* 
* ==> kubelet <==
* -- Logs begin at Sun 2022-08-28 13:55:12 UTC, end at Sun 2022-08-28 13:58:01 UTC. --
-- No entries --

* 
* ==> storage-provisioner [04f671fdac27] <==
* I0828 12:28:58.534881       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0828 12:29:28.554038       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: i/o timeout

* 
* ==> storage-provisioner [09220f943015] <==
* I0828 12:29:29.826358       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0828 12:29:29.854525       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0828 12:29:29.854564       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0828 12:29:29.878621       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0828 12:29:29.878921       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_18111a5a-27b8-4641-8b79-9b3bf1bd21b5!
I0828 12:29:29.880621       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"f94b549e-4875-4d7d-80e0-777aa373cfb6", APIVersion:"v1", ResourceVersion:"391", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_18111a5a-27b8-4641-8b79-9b3bf1bd21b5 became leader
I0828 12:29:29.980880       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_18111a5a-27b8-4641-8b79-9b3bf1bd21b5!

